"""
ğŸ¬ ë¦´ìŠ¤ ë¶„ì„ Streamlit ì•± (OCR ì œê±° + ë¹ ë¥¸ëª¨ë“œ + ì§€ì—°ì„í¬íŠ¸)
"""

import streamlit as st
import asyncio
import os
import re
import time
from datetime import datetime
from io import BytesIO
from typing import Optional

from PIL import Image, ImageDraw, ImageFont  # ì½œë¼ì£¼ìš©


# =========================
# ìœ í‹¸: ì ìˆ˜ í‘œì¤€í™” & ë¹„ë™ê¸° ì‹¤í–‰
# =========================
def _is_number(x):
    try:
        float(x)
        return True
    except Exception:
        return False


def normalize_scores(scores):
    if scores is None:
        return {}
    if isinstance(scores, dict):
        return {str(k): float(v) for k, v in scores.items() if _is_number(v)}
    if isinstance(scores, list):
        tmp = {}
        for item in scores:
            if isinstance(item, dict):
                key = item.get("category") or item.get("name") or item.get("label")
                val = item.get("score") or item.get("value") or item.get("val")
                if key is not None and _is_number(val):
                    tmp[str(key)] = float(val)
            elif isinstance(item, (list, tuple)) and len(item) >= 2:
                key, val = item[0], item[1]
                if key is not None and _is_number(val):
                    tmp[str(key)] = float(val)
        return tmp
    return {}


def run_sync(coro):
    """Streamlit í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ì½”ë£¨í‹´ ì‹¤í–‰"""
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = None
    if loop and loop.is_running():
        new_loop = asyncio.new_event_loop()
        try:
            return new_loop.run_until_complete(coro)
        finally:
            new_loop.close()
    else:
        return asyncio.run(coro)


# =========================
# API í‚¤ í•¸ë“¤ë§ (ì„¸ì…˜ ì…ë ¥ìš©)
# =========================
def _apply_api_keys(openai_key: str = "", gemini_key: str = "", claude_key: str = ""):
    if openai_key:
        os.environ["OPENAI_API_KEY"] = openai_key
    else:
        os.environ.pop("OPENAI_API_KEY", None)
    if gemini_key:
        os.environ["GEMINI_API_KEY"] = gemini_key
    else:
        os.environ.pop("GEMINI_API_KEY", None)
    if claude_key:
        os.environ["CLAUDE_API_KEY"] = claude_key
    else:
        os.environ.pop("CLAUDE_API_KEY", None)


def _load_default_keys_from_env_and_secrets():
    def _get(name, env_name):
        try:
            return st.secrets.get(name, "")
        except Exception:
            return os.environ.get(env_name, "")
    return {
        "openai": _get("OPENAI_API_KEY", "OPENAI_API_KEY"),
        "gemini": _get("GEMINI_API_KEY", "GEMINI_API_KEY"),
        "claude": _get("CLAUDE_API_KEY", "CLAUDE_API_KEY"),
    }


# =========================
# contact_sheet: ìƒ˜í”Œë§ + PNG/PDF
# =========================
def sample_evenly(paths, limit: int):
    if not paths:
        return []
    if limit <= 0 or limit >= len(paths):
        return paths
    step = max(1, len(paths) // limit)
    return paths[::step][:limit]


def make_contact_sheet(
    image_paths,
    cols: int = 5,
    thumb_width: int = 300,
    pad: int = 8,
    bg=(255, 255, 255),
    annotate: bool = False,
    font_path: Optional[str] = None,
    font_size: int = 16,
    draw_border: bool = False,
):
    if not image_paths:
        raise ValueError("image_paths is empty")

    thumbs = []
    for p in image_paths:
        if not os.path.exists(p):
            continue
        im = Image.open(p).convert("RGB")
        w, h = im.size
        new_h = max(1, int(h * (thumb_width / float(w))))
        im = im.resize((thumb_width, new_h), Image.LANCZOS)
        thumbs.append((os.path.basename(p), im))
    if not thumbs:
        raise ValueError("no readable images")

    cols = max(1, int(cols))
    rows = (len(thumbs) + cols - 1) // cols
    row_heights = []
    for r in range(rows):
        row_imgs = [im for _, im in thumbs[r * cols:(r + 1) * cols]]
        row_heights.append(max(img.size[1] for img in row_imgs))

    sheet_w = cols * thumb_width + (cols + 1) * pad
    sheet_h = sum(row_heights) + (rows + 1) * pad
    sheet = Image.new("RGB", (sheet_w, sheet_h), bg)
    draw = ImageDraw.Draw(sheet)

    if annotate:
        try:
            font = ImageFont.truetype(font_path, font_size) if font_path else ImageFont.load_default()
        except Exception:
            font = ImageFont.load_default()
    else:
        font = None

    y = pad
    idx = 0
    border_color = (200, 200, 200)
    label_bg = (255, 255, 255)
    label_fg = (0, 0, 0)

    for r in range(rows):
        x = pad
        for c in range(cols):
            if idx >= len(thumbs):
                break
            name, im = thumbs[idx]
            sheet.paste(im, (x, y))
            if draw_border:
                draw.rectangle([x, y, x + im.size[0] - 1, y + im.size[1] - 1], outline=border_color, width=1)
            if annotate and font is not None:
                lh = font_size + 6
                ly1 = y + im.size[1] - lh
                ly2 = y + im.size[1]
                draw.rectangle([x, ly1, x + im.size[0], ly2], fill=label_bg)
                draw.text((x + 4, ly1 + 3), name, fill=label_fg, font=font)
            x += thumb_width + pad
            idx += 1
        y += row_heights[r] + pad
    return sheet


def build_contact_sheet_bytes(
    image_paths,
    cols: int = 5,
    thumb_width: int = 300,
    pad: int = 8,
    bg=(255, 255, 255),
    annotate: bool = False,
    font_path: Optional[str] = None,
    font_size: int = 16,
    draw_border: bool = False,
    pdf_resolution: float = 150.0,
):
    sheet = make_contact_sheet(
        image_paths, cols=cols, thumb_width=thumb_width, pad=pad, bg=bg,
        annotate=annotate, font_path=font_path, font_size=font_size, draw_border=draw_border
    )
    png_buf = BytesIO()
    sheet.save(png_buf, format="PNG")
    png_bytes = png_buf.getvalue()

    pdf_buf = BytesIO()
    sheet.convert("RGB").save(pdf_buf, format="PDF", resolution=pdf_resolution)
    pdf_bytes = pdf_buf.getvalue()
    return png_bytes, pdf_bytes


# =========================
# í˜ì´ì§€ ì„¤ì • & ìŠ¤íƒ€ì¼
# =========================
st.set_page_config(
    page_title="ğŸ¬ ë¦´ìŠ¤ ë¶„ì„ê¸°",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
.main-header {
    text-align: center;
    color: #FF6B6B;
    font-size: 3rem;
    margin-bottom: 2rem;
}
.metric-container {
    background: #f0f2f6;
    padding: 1rem;
    border-radius: 10px;
    margin: 0.5rem 0;
}
.feedback-box {
    background: #e8f4fd;
    padding: 1.5rem;
    border-radius: 10px;
    border-left: 5px solid #1f77b4;
}
</style>
""", unsafe_allow_html=True)


# =========================
# ì„¸ì…˜ ìƒíƒœ
# =========================
def init_session_state():
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    if "current_analysis" not in st.session_state:
        st.session_state.current_analysis = None
    if "api_keys" not in st.session_state:
        st.session_state.api_keys = _load_default_keys_from_env_and_secrets()
        _apply_api_keys(
            st.session_state.api_keys.get("openai", ""),
            st.session_state.api_keys.get("gemini", ""),
            st.session_state.api_keys.get("claude", ""),
        )


@st.cache_resource
def get_analyzer():
    """ì§€ì—° ì„í¬íŠ¸ë¡œ UI ì•ˆì „ ë¶€íŒ…"""
    try:
        from analyzer import ReelAnalyzer  # ì—¬ê¸°ì„œë§Œ ì„í¬íŠ¸
        return ReelAnalyzer()
    except Exception as e:
        st.warning(f"Analyzer ë¡œë“œ ì‹¤íŒ¨(ì„ì‹œ ë”ë¯¸ ì‚¬ìš©): {e}")

        class _Dummy:
            async def analyze_video(self, **kwargs):
                return {
                    "overall_score": 7,
                    "scores": {
                        "visual_appeal": 7, "content_structure": 7,
                        "trend_fit": 6, "emotional_impact": 7, "viral_potential": 6
                    },
                    "final_feedback_text": "ë”ë¯¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì˜ì¡´ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.",
                    "specific_improvements": ["ì¸íŠ¸ë¡œë¥¼ ë” ì§§ê²Œ", "CTA ìë§‰ ì¶”ê°€"],
                    "next_steps": ["ì”¬ ì „í™˜ ì‹¤í—˜", "í›„í‚¹ ë¬¸êµ¬ í…ŒìŠ¤íŠ¸"],
                    "frame_paths": [], "asr_text": "", "asr_segments": []
                }

        return _Dummy()


# =========================
# íŒŒì¼ ì €ì¥
# =========================
def _sanitize_filename(name: str) -> str:
    name = os.path.basename(name)
    name = re.sub(r'[^A-Za-z0-9._-]+', '_', name)
    return name or "video"


def save_uploaded_file(uploaded_file):
    upload_dir = "uploads"
    os.makedirs(upload_dir, exist_ok=True)
    base, ext = os.path.splitext(_sanitize_filename(uploaded_file.name))
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_name = f"{base}_{ts}{ext or '.mp4'}"
    file_path = os.path.join(upload_dir, safe_name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path


# =========================
# ë©”ì¸
# =========================
def main():
    init_session_state()

    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ¬ ë¦´ìŠ¤ ë¶„ì„ê¸°</h1>', unsafe_allow_html=True)
    st.markdown("**AIê°€ ë‹¹ì‹ ì˜ ë¦´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³  ê°œì„  ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤**")

    # ì‚¬ì´ë“œë°”: í‚¤ ì…ë ¥ + ë¶„ì„/ì¶”ì¶œ ì˜µì…˜ + ì†ë„
    with st.sidebar:
        st.header("ğŸ” API í‚¤ ì…ë ¥ (ì„¸ì…˜ì—ë§Œ ì €ì¥)")
        #openai_key = st.text_input("OpenAI API Key", value=st.session_state.api_keys.get("openai", ""), type="password", placeholder="sk-...")
        gemini_key = st.text_input("Gemini API Key", value=st.session_state.api_keys.get("gemini", ""), type="password", placeholder="AIza...")
        #claude_key = st.text_input("Claude API Key", value=st.session_state.api_keys.get("claude", ""), type="password")

        col_a, col_b = st.columns(2)
        with col_a:
            if st.button("í‚¤ ì ìš©", use_container_width=True):
                st.session_state.api_keys = {
                    #"openai": openai_key.strip(),
                    "gemini": gemini_key.strip(),
                   # "claude": claude_key.strip(),
                }
                _apply_api_keys(**{
                   # "openai_key": st.session_state.api_keys["openai"],
                    "gemini_key": st.session_state.api_keys["gemini"],
                   # "claude_key": st.session_state.api_keys["claude"],
                })
                st.cache_resource.clear()  # analyzer ì¬ì´ˆê¸°í™”
                st.success("âœ… í‚¤ ì ìš© ì™„ë£Œ")
        with col_b:
            if st.button("í‚¤ ì‚­ì œ", use_container_width=True):
                st.session_state.api_keys = {"openai": "", "gemini": "", "claude": ""}
                _apply_api_keys("", "", "")
                st.cache_resource.clear()
                st.warning("ğŸ”’ í‚¤ ì œê±°ë¨")
        st.caption("â€» í‚¤ëŠ” ì´ ì„¸ì…˜ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨í•˜ë©´ ì´ˆê¸°í™”ë¼ìš”.")

        st.header("âš™ï¸ ê¸°ë³¸ ì„¤ì •")
        teacher_options = {
            "ì •ì„ ìƒë‹˜": "teacher_jung",
            "ê¹€ì„ ìƒë‹˜": "teacher_kim",
            "ì´ì„ ìƒë‹˜": "teacher_lee",
            "ë°•ì„ ìƒë‹˜": "teacher_park",
        }
        selected_teacher = st.selectbox("ğŸ‘¨â€ğŸ« ì„ ìƒë‹˜ ì„ íƒ", options=list(teacher_options.keys()))
        teacher_id = teacher_options[selected_teacher]

        model_options = ["gemini", "openai"]
        selected_model = st.selectbox("ğŸ¤– AI ëª¨ë¸", options=model_options)

        st.subheader("ğŸ¯ ë¶„ì„ ì˜µì…˜")
        detailed_analysis = st.checkbox("ìƒì„¸ ë¶„ì„", value=True)
        include_suggestions = st.checkbox("ê°œì„  ì œì•ˆ", value=True)

        st.subheader("ğŸ§° ì¶”ì¶œ ì˜µì…˜")
        do_asr = st.checkbox("ì˜¤ë””ì˜¤ â†’ í…ìŠ¤íŠ¸(ASR) ì‹¤í–‰", value=True)
        asr_model_size = st.selectbox("ASR ëª¨ë¸ í¬ê¸°", ["tiny", "base", "small", "medium", "large-v3"], index=2)
        do_frames = st.checkbox("í”„ë ˆì„ ìº¡ì³ ì‹¤í–‰", value=True)
        frame_interval = st.slider("í”„ë ˆì„ ê°„ê²©(ì´ˆ)", 0.5, 5.0, 2.0, 0.5)

        st.subheader("âš¡ ì†ë„")
        fast_mode = st.checkbox("ë¹ ë¥¸ ëª¨ë“œ(í’ˆì§ˆâ†“, ì†ë„â†‘)", value=True)
        if fast_mode:
            # ë¹ ë¥¸ í”„ë¦¬ì…‹: ASR ìƒëµ + í”„ë ˆì„ ê°„ê²© ëŠ˜ë¦¼
            do_asr = False
            frame_interval = max(frame_interval, 3.0)

        with st.expander("ğŸ©º ì§„ë‹¨ (Diagnostics)"):
            import shutil, sys
            st.write("Python:", sys.version.split()[0])
            st.write("ffmpeg:", "OK" if shutil.which("ffmpeg") else "NOT FOUND")
            for lib in ["opencv_python_headless", "faster_whisper", "google.generativeai"]:
                try:
                    __import__(lib)
                    st.write(f"{lib}: OK")
                except Exception as e:
                    st.write(f"{lib}: âŒ {e.__class__.__name__}")

    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([1, 1])

    with col1:
        st.header("ğŸ“¤ ë¹„ë””ì˜¤ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "ë¦´ìŠ¤ ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["mp4", "avi", "mov", "mkv"],
            help="ìµœëŒ€ 100MB, 5ë¶„ ì´ë‚´ ì˜ìƒ"
        )

        if uploaded_file:
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
            st.video(uploaded_file)

            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True, key="btn_analyze"):
                analyze_video(
                    uploaded_file=uploaded_file,
                    teacher_id=teacher_id,
                    model_name=selected_model,
                    detailed_analysis=detailed_analysis,
                    include_suggestions=include_suggestions,
                    do_asr=do_asr,
                    asr_model_size=asr_model_size,
                    do_frames=do_frames,
                    frame_interval=frame_interval,
                    fast_mode=fast_mode,
                )

    with col2:
        st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        if st.session_state.current_analysis:
            display_analysis_results(st.session_state.current_analysis)
        else:
            st.info("ğŸ‘ˆ ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")

    # í•˜ë‹¨ - ë¶„ì„ ì´ë ¥
    st.header("ğŸ“ˆ ë¶„ì„ ì´ë ¥")
    display_analysis_history()


# =========================
# ë™ì‘ ë£¨í‹´
# =========================
def analyze_video(
    uploaded_file,
    teacher_id: str,
    model_name: str,
    detailed_analysis: bool,
    include_suggestions: bool,
    do_asr: bool,
    asr_model_size: str,
    do_frames: bool,
    frame_interval: float,
    fast_mode: bool = False,
):
    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        # 1) íŒŒì¼ ì €ì¥
        status_text.text("ğŸ“ íŒŒì¼ ì €ì¥ ì¤‘...")
        progress_bar.progress(10)
        file_path = save_uploaded_file(uploaded_file)

        # 2) ìº¡ì³/ASR ëª¨ë“ˆ ì§€ì—° ì„í¬íŠ¸
        try:
            from capture import capture_frames, asr_transcribe
        except Exception as e:
            st.error(
                "âš ï¸ ìº¡ì³ ëª¨ë“ˆ(capture.py) ë˜ëŠ” ì˜ì¡´ íŒ¨í‚¤ì§€ ë¡œë“œ ì‹¤íŒ¨.\n"
                f"ì‚¬ìœ : {e}\n\n"
                "í•„ìš” íŒ¨í‚¤ì§€: opencv-python-headless, faster-whisper, ê·¸ë¦¬ê³  ì‹œìŠ¤í…œ ffmpeg ë˜ëŠ” imageio-ffmpeg"
            )
            progress_bar.empty()
            status_text.empty()
            return

        # 3) ì˜¤ë””ì˜¤/í”„ë ˆì„ ì¶”ì¶œ
        extracted = {"asr_text": "", "asr_segments": [], "frame_paths": [], "fast_mode": fast_mode}

        # í”„ë ˆì„
        frames_dir = os.path.join("captures", os.path.splitext(os.path.basename(file_path))[0])
        if do_frames:
            status_text.text("ğŸ í”„ë ˆì„ ìº¡ì³ ì¤‘...")
            progress_bar.progress(35)
            frame_paths = capture_frames(
                video_path=file_path, interval_sec=frame_interval, out_dir=frames_dir
            )
            extracted["frame_paths"] = frame_paths
        else:
            frame_paths = []

        # ASR
        if do_asr:
            status_text.text("ğŸµ ì˜¤ë””ì˜¤ â†’ í…ìŠ¤íŠ¸(ASR) ì¤‘...")
            progress_bar.progress(55)
            try:
                # ìƒˆ capture.py(ê¶Œì¥) ì‹œê·¸ë‹ˆì²˜
                asr = asr_transcribe(
                    file_path,
                    engine="faster-whisper",
                    model_size=asr_model_size,
                    beam_size=1 if fast_mode else 5,   # ë¹ ë¥¸ ëª¨ë“œì—ì„œ ì†ë„â†‘
                )
            except TypeError:
                # êµ¬ ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜
                asr = asr_transcribe(file_path, engine="faster-whisper", model_size=asr_model_size)
            extracted["asr_text"] = asr.get("text", "")
            extracted["asr_segments"] = asr.get("segments", [])

        # 4) ë¶„ì„ê¸° ì‹¤í–‰
        status_text.text("ğŸ¤– AI ë¶„ì„ ì¤‘...")
        progress_bar.progress(75)
        analyzer = get_analyzer()

        try:
            # ìµœì‹  analyzerëŠ” fast_mode & pre_context ì§€ì›
            result = run_sync(
            analyzer.analyze_video(
                file_path=file_path,
                teacher_id=teacher_id,
                model_name=model_name,
                detailed=detailed_analysis,
                include_suggestions=include_suggestions,
                pre_context=extracted,   # extracted ì•ˆì— extracted["fast_mode"]=fast_mode ì´ë¯¸ ìˆìŒ
            )
        )
        except TypeError:
            # êµ¬ë²„ì „ í˜¸í™˜(í•´ë‹¹ ì¸ì ì œê±°)
            result = run_sync(
                analyzer.analyze_video(
                    file_path=file_path,
                    teacher_id=teacher_id,
                    model_name=model_name,
                    detailed=detailed_analysis,
                    include_suggestions=include_suggestions,
                )
            )

        progress_bar.progress(90)
        status_text.text("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")

        # ì¶”ì¶œ ê²°ê³¼ ë³‘í•©(í™”ë©´ í‘œì‹œ/ì½œë¼ì£¼ ìš©)
        if isinstance(result, dict):
            result.setdefault("frame_paths", extracted["frame_paths"])
            result.setdefault("asr_text", extracted["asr_text"])
            result.setdefault("asr_segments", extracted["asr_segments"])

        # ì„¸ì…˜ ì €ì¥ & ì´ë ¥ ê¸°ë¡
        st.session_state.current_analysis = result
        st.session_state.analysis_history.append({
            "timestamp": datetime.now().isoformat(),
            "filename": uploaded_file.name,
            "teacher": teacher_id,
            "model": model_name,
            "score": (result or {}).get("overall_score", 0),
            "frames": extracted["frame_paths"],
        })

        progress_bar.progress(100)
        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
        time.sleep(0.6)
        st.rerun()

    except Exception as e:
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        progress_bar.empty()
        status_text.empty()


# =========================
# í™”ë©´ í‘œì‹œ
# =========================
def display_analysis_results(result):
    if not isinstance(result, dict):
        st.error("âŒ ë¶„ì„ ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    if result.get("error"):
        st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error_message') or result['error']}")
        return

    # ì „ì²´ ì ìˆ˜
    overall_score = result.get("overall_score", 0)
    st.metric(
        label="ğŸ† ì „ì²´ ì ìˆ˜",
        value=f"{overall_score}/10",
        delta=("í›Œë¥­í•´ìš”!" if _is_number(overall_score) and float(overall_score) >= 8
               else "ì¢‹ì•„ìš”!" if _is_number(overall_score) and float(overall_score) >= 6
               else "ê°œì„  í•„ìš”")
    )

    # ì„¸ë¶€ ì ìˆ˜
    raw_scores = result.get("scores", {})
    scores = normalize_scores(raw_scores)
    if scores:
        st.subheader("ğŸ“Š ì„¸ë¶€ ì ìˆ˜")
        num = len(scores)
        cols_metrics = st.columns(min(4, max(1, num)))
        for i, (category, score) in enumerate(scores.items()):
            with cols_metrics[i % len(cols_metrics)]:
                st.metric(
                    label=str(category).replace('_', ' ').title(),
                    value=f"{score}/10"
                )
    else:
        st.info("ì„¸ë¶€ ì ìˆ˜ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # í”¼ë“œë°±
    if result.get("final_feedback_text"):
        st.markdown('<div class="feedback-box">', unsafe_allow_html=True)
        st.subheader("ğŸ’¬ ì„ ìƒë‹˜ í”¼ë“œë°±")
        st.write(result["final_feedback_text"])
        st.markdown("</div>", unsafe_allow_html=True)

    if result.get("specific_improvements"):
        st.subheader("ğŸ¯ êµ¬ì²´ì  ê°œì„ ì‚¬í•­")
        for i, improvement in enumerate(result["specific_improvements"], 1):
            st.write(f"{i}. {improvement}")

    if result.get("next_steps"):
        st.subheader("ğŸš€ ë‹¤ìŒì— ì‹œë„í•´ë³´ì„¸ìš”")
        for step in result["next_steps"]:
            st.write(f"â€¢ {step}")

    # ASR í‘œì‹œ
    with st.expander("ğŸ”Š ASR í…ìŠ¤íŠ¸ ë³´ê¸°"):
        asr_text = result.get("asr_text") or ""
        if asr_text:
            st.code(asr_text[:5000])
        else:
            st.caption("ASR ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # í”„ë ˆì„ ì½œë¼ì£¼
    frames = result.get("frame_paths") or (
        st.session_state.analysis_history[-1].get("frames", [])
        if st.session_state.analysis_history else []
    )
    if frames:
        st.subheader("ğŸï¸ í”„ë ˆì„ ì½œë¼ì£¼")
        max_n = max(1, min(100, len(frames)))   # ìµœëŒ€ 100 ë˜ëŠ” ì „ì²´ ìˆ˜
        min_n = 1 if len(frames) < 20 else 20
        default_n = min(50, max_n)
        if default_n < min_n:
            default_n = min_n
        limit = st.slider(
            "í¬í•¨í•  í”„ë ˆì„ ìˆ˜",
            min_value=min_n,
            max_value=max_n,
            value=default_n,
            step=1 if max_n < 20 else 10,
        )
        n_cols = st.slider("ì—´ ê°œìˆ˜", 3, 8, 5, 1)
        thumb_w = st.slider("ì¸ë„¤ì¼ ê°€ë¡œ(px)", 160, 480, 280, 20)
        annotate = st.checkbox("íŒŒì¼ëª… í‘œì‹œ", value=False)
        border = st.checkbox("í…Œë‘ë¦¬", value=True)

        sampled = sample_evenly(frames, limit)

        if st.button("ì½œë¼ì£¼ PNG/PDF ìƒì„±"):
            png_bytes, pdf_bytes = build_contact_sheet_bytes(
                sampled, cols=n_cols, thumb_width=thumb_w, annotate=annotate, draw_border=border
            )
            st.image(png_bytes, caption="Contact Sheet Preview", use_container_width=True)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            st.download_button("â¬‡ï¸ PNG ë‹¤ìš´ë¡œë“œ", data=png_bytes, file_name=f"contact_sheet_{ts}.png", mime="image/png")
            st.download_button("â¬‡ï¸ PDF ë‹¤ìš´ë¡œë“œ", data=pdf_bytes, file_name=f"contact_sheet_{ts}.pdf", mime="application/pdf")


def display_analysis_history():
    if not st.session_state.analysis_history:
        st.info("ì•„ì§ ë¶„ì„ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    recent = st.session_state.analysis_history[-5:]
    for item in reversed(recent):
        with st.expander(f"ğŸ“¹ {item['filename']} (ì ìˆ˜: {item['score']}/10)"):
            col1, col2, col3 = st.columns(3)
            col1.write(f"**ì¼ì‹œ:** {item['timestamp'][:19]}")
            col2.write(f"**ì„ ìƒë‹˜:** {item['teacher']}")
            col3.write(f"**ëª¨ë¸:** {item['model']}")


# =========================
if __name__ == "__main__":
    main()
